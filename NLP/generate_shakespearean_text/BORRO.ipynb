{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled34.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnRTD7ImCk87IubDfxzPyH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bitblayde/Machine-and-Deep-learning-projects/blob/main/NLP/generate_shakespearean_text/statelessRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsy7XRxbAAfs"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "\n",
        "file = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
        "\n",
        "with open(file) as f:\n",
        "  text = f.read()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlURNk-CBIfY"
      },
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(text)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UOTv8bFBJGh",
        "outputId": "048ce16b-671a-41c2-d3fb-610761eccf21"
      },
      "source": [
        "tokenizer.texts_to_sequences([\"Hello\"])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[7, 2, 12, 12, 4]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "JnAMQTsqBJfo",
        "outputId": "f17c09a2-7f67-4e56-a33f-fb3b7b699219"
      },
      "source": [
        "''.join(tokenizer.sequences_to_texts([[7, 2, 12, 12, 4]]))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'h e l l o'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnIrD1TiBJmM",
        "outputId": "d3e513ef-3040-436f-faf6-d640054a3552"
      },
      "source": [
        "n_characters = len(tokenizer.word_counts)\n",
        "n_characters, tokenizer.word_counts"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39,\n",
              " OrderedDict([('f', 17567),\n",
              "              ('i', 57369),\n",
              "              ('r', 53758),\n",
              "              ('s', 54219),\n",
              "              ('t', 74024),\n",
              "              (' ', 169892),\n",
              "              ('c', 19443),\n",
              "              ('z', 554),\n",
              "              ('e', 100652),\n",
              "              ('n', 53608),\n",
              "              (':', 10316),\n",
              "              ('\\n', 40000),\n",
              "              ('b', 14082),\n",
              "              ('o', 71279),\n",
              "              ('w', 21115),\n",
              "              ('p', 12449),\n",
              "              ('d', 33447),\n",
              "              ('a', 63326),\n",
              "              ('y', 22166),\n",
              "              ('u', 29897),\n",
              "              ('h', 54378),\n",
              "              (',', 19846),\n",
              "              ('m', 25083),\n",
              "              ('k', 8672),\n",
              "              ('.', 7885),\n",
              "              ('l', 37215),\n",
              "              ('v', 8591),\n",
              "              ('?', 2462),\n",
              "              (\"'\", 6187),\n",
              "              ('g', 15755),\n",
              "              (';', 3628),\n",
              "              ('!', 2172),\n",
              "              ('j', 948),\n",
              "              ('-', 1897),\n",
              "              ('q', 840),\n",
              "              ('x', 641),\n",
              "              ('&', 3),\n",
              "              ('3', 27),\n",
              "              ('$', 1)]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWZpWRtGBJpa",
        "outputId": "536b7723-3835-4342-c662-95535f4e9f18"
      },
      "source": [
        "tokenizer.document_count"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL50hLHWBJr0"
      },
      "source": [
        "text_encoded = np.array(tokenizer.texts_to_sequences(text))\n",
        "text_encoded = text_encoded.reshape(-1)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z40UP8-hBJtz",
        "outputId": "d0f394e5-a214-4301-8159-2455e30afc86"
      },
      "source": [
        "text_encoded"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([20,  6,  9, ..., 21, 27, 11])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcmRPVc-BJxe"
      },
      "source": [
        "text_encoded -= 1"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01jJbKhnBJ1U"
      },
      "source": [
        "window_size = 101\n",
        "buffer_size = 20000\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "train_size = 80*tokenizer.document_count // 100\n",
        "dataset_window = tf.data.Dataset.from_tensor_slices(text_encoded[:train_size])\n",
        "\n",
        "dataset_window = dataset_window.window(size=window_size, stride=1, drop_remainder=True)\n",
        "\n",
        "dataset_window = dataset_window.flat_map(lambda X : X.batch(window_size))\n",
        "dataset_window = dataset_window.shuffle(buffer_size=buffer_size).batch(batch_size)\n",
        "dataset_window = dataset_window.map(lambda X : (X[:, :-1], X[:, 1:]))\n",
        "dataset = dataset_window.map(lambda X, y : (tf.one_hot(X, n_characters), y))\n",
        "\n",
        "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbecCSqnBJ3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb8a3202-cf46-4bae-9e04-a17d2211d3b9"
      },
      "source": [
        "for X, y in dataset.take(1):\n",
        "  print(X.shape, y.shape)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 39) (64, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l00ygeA2s_Ci"
      },
      "source": [
        "64 as batch, 100 as window size, and 39 as cardinality of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9IvNjWkBJ8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14922e0a-0b2b-45b2-c45e-4d5b7a43a430"
      },
      "source": [
        "epochs = 20\n",
        "model = keras.Sequential([\n",
        "                          keras.layers.GRU(256, dropout=0.2, input_shape=[None, n_characters], return_sequences=True),\n",
        "                          keras.layers.GRU(512, dropout=0.2, return_sequences=True),\n",
        "                          keras.layers.GRU(256, dropout=0.2, return_sequences=True),\n",
        "                          keras.layers.TimeDistributed(keras.layers.Dense(n_characters)),\n",
        "                          keras.layers.Activation(\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
        "model.fit(dataset, epochs=epochs)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "139/139 [==============================] - 11s 40ms/step - loss: 2.6880\n",
            "Epoch 2/20\n",
            "139/139 [==============================] - 7s 40ms/step - loss: 2.2170\n",
            "Epoch 3/20\n",
            "139/139 [==============================] - 7s 40ms/step - loss: 2.0344\n",
            "Epoch 4/20\n",
            "139/139 [==============================] - 7s 41ms/step - loss: 1.9264\n",
            "Epoch 5/20\n",
            "139/139 [==============================] - 7s 40ms/step - loss: 1.8644\n",
            "Epoch 6/20\n",
            "139/139 [==============================] - 7s 41ms/step - loss: 1.8234\n",
            "Epoch 7/20\n",
            "139/139 [==============================] - 7s 41ms/step - loss: 1.7895\n",
            "Epoch 8/20\n",
            "139/139 [==============================] - 7s 40ms/step - loss: 1.7664\n",
            "Epoch 9/20\n",
            "139/139 [==============================] - 7s 41ms/step - loss: 1.7450\n",
            "Epoch 10/20\n",
            "139/139 [==============================] - 7s 40ms/step - loss: 1.7342\n",
            "Epoch 11/20\n",
            "139/139 [==============================] - 7s 41ms/step - loss: 1.7166\n",
            "Epoch 12/20\n",
            "139/139 [==============================] - 7s 41ms/step - loss: 1.7044\n",
            "Epoch 13/20\n",
            "139/139 [==============================] - 7s 40ms/step - loss: 1.6911\n",
            "Epoch 14/20\n",
            "139/139 [==============================] - 7s 41ms/step - loss: 1.6825\n",
            "Epoch 15/20\n",
            "139/139 [==============================] - 7s 41ms/step - loss: 1.6739\n",
            "Epoch 16/20\n",
            "139/139 [==============================] - 7s 41ms/step - loss: 1.6645\n",
            "Epoch 17/20\n",
            "139/139 [==============================] - 7s 40ms/step - loss: 1.6588\n",
            "Epoch 18/20\n",
            "139/139 [==============================] - 7s 40ms/step - loss: 1.6525\n",
            "Epoch 19/20\n",
            "139/139 [==============================] - 7s 41ms/step - loss: 1.6488\n",
            "Epoch 20/20\n",
            "139/139 [==============================] - 7s 41ms/step - loss: 1.6412\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3f1ed89510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cByyC5eBKAw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e074255-3f61-41ee-f0bd-d44e206e6b5e"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 15448224018725612992\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14509932544\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 13031767698477494428\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4pYt6e7HoLM",
        "outputId": "8d36a52a-d452-4a86-bcbb-7213115d0c4d"
      },
      "source": [
        "def preprocess(input):\n",
        "  return tf.one_hot(np.array(tokenizer.texts_to_sequences(input))-1, n_characters)\n",
        "\n",
        "def next_character(input, t=1):\n",
        "  preprocessing_text = preprocess([input])\n",
        "  X_new = model.predict(preprocessing_text)\n",
        "  X_new = X_new[0, -1:, :]\n",
        "  prob = tf.math.log(X_new) / t\n",
        "  character = tf.random.categorical(prob, num_samples=1)+1\n",
        "  return tokenizer.sequences_to_texts(character.numpy())[0]\n",
        "\n",
        "string = \"Hello, my na\"\n",
        "string += next_character(string, t=1)\n",
        "string += next_character(string, t=1)\n",
        "print(string)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello, my name\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DERh7dGFBKC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c55c9bc-c8f1-4c34-813d-1a2efeb9a49f"
      },
      "source": [
        "def generate_text(n_characters = 100, text = \"a\", t = 1):\n",
        "  for _ in range(n_characters):\n",
        "    text += next_character(text, t=t)\n",
        "  return text\n",
        "\n",
        "\n",
        "print(generate_text(n_characters = 50, text = \"t\", t = 1))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "that come the mile weach of the news.\n",
            "\n",
            "second murde\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
