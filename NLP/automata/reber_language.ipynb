{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled41.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPw5fKjSkrlEx8G2J4XkMxF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bitblayde/Machine-and-Deep-learning-projects/blob/main/NLP/automata/reber_language.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1s0vyaQjQf-"
      },
      "source": [
        "\n",
        "This exercise attempts to resolve the exercise 16.8 from the Hands-on ML book.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofgFW2PePYAR"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "reber_grammar = [ \n",
        "                 [(\"B\", 1)],\n",
        "                 [(\"T\", 2), (\"P\", 3)],\n",
        "                 [(\"S\", 2), (\"X\", 4)],\n",
        "                 [(\"T\", 3), (\"V\", 5)],\n",
        "                 [(\"X\", 3), (\"S\", 6)],\n",
        "                 [(\"P\", 4), (\"V\", 6)],\n",
        "                 [(\"E\", None)]\n",
        "]\n",
        "\n",
        "embedded_reber_grammar = [\n",
        "                    [(\"B\", 1)],\n",
        "                    [(\"T\", 2), (\"P\", 3)],  \n",
        "                    [(reber_grammar, 4)],    \n",
        "                    [(reber_grammar, 5)],\n",
        "                    [(\"T\", 6)],\n",
        "                    [(\"P\", 6)],\n",
        "                    [(\"E\", None)]\n",
        "]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQMbuKyyUcFq",
        "outputId": "95b58198-ae67-4b2c-8791-7d3fc9971742"
      },
      "source": [
        "def generate_reber_grammar(grammar):\n",
        "  output = []\n",
        "  state = 0\n",
        "\n",
        "  while state is not None:\n",
        "    index = np.random.randint(len(grammar[state]))\n",
        "\n",
        "    node, state = grammar[state][index]\n",
        "\n",
        "    if isinstance(node, list):\n",
        "      node = generate_reber_grammar(node)\n",
        "\n",
        "    output.append(node)\n",
        "\n",
        "  return \"\".join(output)\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "for _ in range(10):\n",
        "  print(generate_reber_grammar(embedded_reber_grammar), end=\" \")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BTBPTTTVPXTVPXTTVPSETE BPBPTVPSEPE BPBPVVEPE BPBPVPXVVEPE BPBTXXTTTTVVEPE BPBPVPSEPE BPBTXXVPSEPE BPBTSSSSSSSXSEPE BTBPVVETE BPBTXXVVEPE "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "AoeigU8T4KbR",
        "outputId": "4a1496b7-71eb-421a-95f5-731d3658f5cf"
      },
      "source": [
        "vocabulary = \"BEPSTVX\"\n",
        "def generate_non_reber_grammar(grammar, vocab):\n",
        "  reber_string = generate_reber_grammar(grammar)\n",
        "  idx = np.random.randint(len(reber_string))\n",
        "  to_change = np.random.choice( list(set(vocab) - set(reber_string[idx])) )\n",
        "  non_reber_string = reber_string[:idx] + to_change + reber_string[idx+1:]\n",
        "  return non_reber_string\n",
        "  \n",
        "generate_non_reber_grammar(embedded_reber_grammar, vocabulary)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'BPBPVPSEBE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egk8LbbpI_th"
      },
      "source": [
        "def char_to_int(gammar, vocabulary):\n",
        "  return [vocabulary.index(i) for i in gammar]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF67BkQb3WmP"
      },
      "source": [
        "import tensorflow as tf\n",
        "def get_dataset(size, gammar, vocabulary):\n",
        "  reber_grammar = [ char_to_int(generate_reber_grammar(gammar), vocabulary) for i in range(size//2) ]\n",
        "  non_reber_grammar = [ char_to_int(generate_non_reber_grammar(gammar, vocabulary), vocabulary) for i in range(size - (size //2) ) ]\n",
        "\n",
        "  dataset = reber_grammar + non_reber_grammar\n",
        "\n",
        "  y = [[1.] for i in range(len(reber_grammar)) ] + [[0.] for i in range(len(non_reber_grammar)) ]\n",
        "\n",
        "  return tf.ragged.constant(dataset, ragged_rank=1), np.array(y)\n",
        "\n",
        "trainX, trainy = get_dataset(size=8000, gammar=embedded_reber_grammar, vocabulary=vocabulary)\n",
        "valX, valy = get_dataset(size=int(8000*0.3), gammar=embedded_reber_grammar, vocabulary=vocabulary)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY71QRzOM2p8"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "EMBEDDED_SIZE = 5\n",
        "\n",
        "input = tf.keras.Input(shape=[None], dtype=tf.int32, ragged=True)\n",
        "\n",
        "X = tf.keras.layers.Embedding(input_dim=len(vocabulary), output_dim=EMBEDDED_SIZE)(input)\n",
        "X = tf.keras.layers.GRU(units=100, activation='tanh')(X)\n",
        "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(X)\n",
        "model = keras.Model(inputs=input, outputs=output)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pt7zpFjRQrtE",
        "outputId": "49dd6486-b51e-457c-f21f-aec1f5fb4ee2"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "optim = keras.optimizers.SGD(learning_rate=0.02, momentum=0.99, nesterov=True) # Are IID\n",
        "model.compile(optimizer=optim, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(trainX, trainy, epochs=15, validation_data=(valX, valy))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/gru/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/gru/RaggedToTensor/boolean_mask/GatherV2:0\", shape=(None, 5), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/gru/RaggedToTensor/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "250/250 [==============================] - 17s 62ms/step - loss: 0.6933 - accuracy: 0.5045 - val_loss: 0.6796 - val_accuracy: 0.5854\n",
            "Epoch 2/15\n",
            "250/250 [==============================] - 14s 57ms/step - loss: 0.6606 - accuracy: 0.5754 - val_loss: 0.6414 - val_accuracy: 0.5612\n",
            "Epoch 3/15\n",
            "250/250 [==============================] - 14s 54ms/step - loss: 0.6188 - accuracy: 0.6112 - val_loss: 0.5970 - val_accuracy: 0.6725\n",
            "Epoch 4/15\n",
            "250/250 [==============================] - 13s 53ms/step - loss: 0.5031 - accuracy: 0.7385 - val_loss: 0.3814 - val_accuracy: 0.8363\n",
            "Epoch 5/15\n",
            "250/250 [==============================] - 14s 57ms/step - loss: 0.2714 - accuracy: 0.9031 - val_loss: 0.2495 - val_accuracy: 0.9087\n",
            "Epoch 6/15\n",
            "250/250 [==============================] - 14s 58ms/step - loss: 0.1221 - accuracy: 0.9647 - val_loss: 0.0730 - val_accuracy: 0.9846\n",
            "Epoch 7/15\n",
            "250/250 [==============================] - 14s 57ms/step - loss: 0.0655 - accuracy: 0.9861 - val_loss: 0.0599 - val_accuracy: 0.9879\n",
            "Epoch 8/15\n",
            "250/250 [==============================] - 15s 59ms/step - loss: 0.1091 - accuracy: 0.9706 - val_loss: 0.0992 - val_accuracy: 0.9758\n",
            "Epoch 9/15\n",
            "250/250 [==============================] - 14s 56ms/step - loss: 0.1178 - accuracy: 0.9706 - val_loss: 0.0831 - val_accuracy: 0.9846\n",
            "Epoch 10/15\n",
            "250/250 [==============================] - 14s 55ms/step - loss: 0.0709 - accuracy: 0.9852 - val_loss: 0.0627 - val_accuracy: 0.9879\n",
            "Epoch 11/15\n",
            "250/250 [==============================] - 14s 56ms/step - loss: 0.0644 - accuracy: 0.9877 - val_loss: 0.0612 - val_accuracy: 0.9875\n",
            "Epoch 12/15\n",
            "250/250 [==============================] - 15s 58ms/step - loss: 0.0630 - accuracy: 0.9869 - val_loss: 0.0729 - val_accuracy: 0.9825\n",
            "Epoch 13/15\n",
            "250/250 [==============================] - 15s 60ms/step - loss: 0.0652 - accuracy: 0.9859 - val_loss: 0.0867 - val_accuracy: 0.9879\n",
            "Epoch 14/15\n",
            "250/250 [==============================] - 14s 57ms/step - loss: 0.0432 - accuracy: 0.9911 - val_loss: 0.0075 - val_accuracy: 0.9992\n",
            "Epoch 15/15\n",
            "250/250 [==============================] - 14s 56ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.0043 - val_accuracy: 0.9996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5fc7a450d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epmX5E5ZShB_",
        "outputId": "7ba5ad04-edb0-4ae8-c469-688e8c7e7f3d"
      },
      "source": [
        "reber_sample = [\"BTBTSSXXTVVETE\", \"BPBPVPXVPXVPXVVEPE\"]\n",
        "non_reber_sample = [\"BTBTSSPXSETE\", \"BPBPVSPSEPE\"]\n",
        "\n",
        "X_test = reber_sample + non_reber_sample\n",
        "\n",
        "X_test_encoded = tf.ragged.constant( [char_to_int(i, vocabulary) for i in X_test], ragged_rank=1)\n",
        "y_pred = model.predict(X_test_encoded)\n",
        "\n",
        "for i in range(len(y_pred)):\n",
        "    print(\"{}: {:.3f}%\".format(X_test[i], 100 * y_pred[i][0]))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BTBTSSXXTVVETE: 99.734%\n",
            "BPBPVPXVPXVPXVVEPE: 98.781%\n",
            "BTBTSSPXSETE: 0.000%\n",
            "BPBPVSPSEPE: 0.000%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP4WKwcCSj2Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}