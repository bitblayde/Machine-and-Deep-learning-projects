{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled41.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNLY0r5oDXeGr65EYaWTFZH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bitblayde/Machine-and-Deep-learning-projects/blob/main/NLP/automata/reber_language.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1s0vyaQjQf-"
      },
      "source": [
        "\n",
        "This exercise attempts to resolve the exercise 16.8 from the Hands-on ML book.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofgFW2PePYAR"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "reber_grammar = [ \n",
        "                 [(\"B\", 1)],\n",
        "                 [(\"T\", 2), (\"P\", 3)],\n",
        "                 [(\"S\", 2), (\"X\", 4)],\n",
        "                 [(\"T\", 3), (\"V\", 5)],\n",
        "                 [(\"X\", 3), (\"S\", 6)],\n",
        "                 [(\"P\", 4), (\"V\", 6)],\n",
        "                 [(\"E\", None)]\n",
        "]\n",
        "\n",
        "embedded_reber_grammar = [\n",
        "                    [(\"B\", 1)],\n",
        "                    [(\"T\", 2), (\"P\", 3)],  \n",
        "                    [(reber_grammar, 4)],    \n",
        "                    [(reber_grammar, 5)],\n",
        "                    [(\"T\", 6)],\n",
        "                    [(\"P\", 6)],\n",
        "                    [(\"E\", None)]\n",
        "]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQMbuKyyUcFq",
        "outputId": "6798da9f-c825-4be8-f71d-a661baa28c10"
      },
      "source": [
        "def generate_reber_grammar(grammar):\n",
        "  output = []\n",
        "  state = 0\n",
        "\n",
        "  while state is not None:\n",
        "    index = np.random.randint(len(grammar[state]))\n",
        "\n",
        "    node, state = grammar[state][index]\n",
        "\n",
        "    if isinstance(node, list):\n",
        "      node = generate_reber_grammar(node)\n",
        "\n",
        "    output.append(node)\n",
        "\n",
        "  return \"\".join(output)\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "for _ in range(10):\n",
        "  print(generate_reber_grammar(embedded_reber_grammar), end=\" \")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BTBPTTTVPXTVPXTTVPSETE BPBPTVPSEPE BPBPVVEPE BPBPVPXVVEPE BPBTXXTTTTVVEPE BPBPVPSEPE BPBTXXVPSEPE BPBTSSSSSSSXSEPE BTBPVVETE BPBTXXVVEPE "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoeigU8T4KbR",
        "outputId": "426fa619-4a82-4139-bfcb-bbfe20120a68"
      },
      "source": [
        "vocabulary = \"BEPSTVX\"\n",
        "def generate_non_reber_grammar(grammar, vocab):\n",
        "  reber_string = generate_reber_grammar(grammar)\n",
        "  idx = np.random.randint(len(reber_string))\n",
        "  to_change = np.random.choice( list(set(vocab) - set(reber_string[idx])) )\n",
        "  non_reber_string = reber_string[:idx] + to_change + reber_string[idx+1:]\n",
        "  return non_reber_string\n",
        "\n",
        "for _ in range(10):\n",
        "  print(generate_non_reber_grammar(embedded_reber_grammar, vocabulary), end=\" \") "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BPSTXXVPSEPE BTBTVVETE BPBSVVEPE BXBTXSETE BPBPVPSSPE BTBPVVVETE BPBTSXSEEE BPBPTTTPTTTTTVPSEPE BTBTXXTTETVPSETE BBBTXSETE "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egk8LbbpI_th"
      },
      "source": [
        "def char_to_int(gammar, vocabulary):\n",
        "  return [vocabulary.index(i) for i in gammar]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF67BkQb3WmP"
      },
      "source": [
        "import tensorflow as tf\n",
        "def get_dataset(size, gammar, vocabulary):\n",
        "  reber_grammar = [ char_to_int(generate_reber_grammar(gammar), vocabulary) for i in range(size//2) ]\n",
        "  non_reber_grammar = [ char_to_int(generate_non_reber_grammar(gammar, vocabulary), vocabulary) for i in range(size - (size //2) ) ]\n",
        "\n",
        "  dataset = reber_grammar + non_reber_grammar\n",
        "\n",
        "  y = [[1.] for i in range(len(reber_grammar)) ] + [[0.] for i in range(len(non_reber_grammar)) ]\n",
        "\n",
        "  return tf.ragged.constant(dataset, ragged_rank=1), np.array(y)\n",
        "\n",
        "trainX, trainy = get_dataset(size=8000, gammar=embedded_reber_grammar, vocabulary=vocabulary)\n",
        "valX, valy = get_dataset(size=int(8000*0.3), gammar=embedded_reber_grammar, vocabulary=vocabulary)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY71QRzOM2p8"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "EMBEDDED_SIZE = 5\n",
        "\n",
        "input = tf.keras.Input(shape=[None], dtype=tf.int32, ragged=True)\n",
        "\n",
        "X = tf.keras.layers.Embedding(input_dim=len(vocabulary), output_dim=EMBEDDED_SIZE)(input)\n",
        "X = tf.keras.layers.GRU(units=100, activation='tanh')(X)\n",
        "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(X)\n",
        "model = keras.Model(inputs=input, outputs=output)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pt7zpFjRQrtE",
        "outputId": "46d43eca-12a6-42a5-b313-b8fd3ecca768"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "optim = keras.optimizers.SGD(learning_rate=0.02, momentum=0.99, nesterov=True) # Are IID\n",
        "model.compile(optimizer=optim, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(trainX, trainy, epochs=15, validation_data=(valX, valy))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/gru/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/gru/RaggedToTensor/boolean_mask/GatherV2:0\", shape=(None, 5), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/gru/RaggedToTensor/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "250/250 [==============================] - 15s 54ms/step - loss: 0.1874 - accuracy: 0.9434 - val_loss: 0.1894 - val_accuracy: 0.9450\n",
            "Epoch 2/15\n",
            "250/250 [==============================] - 13s 54ms/step - loss: 0.1704 - accuracy: 0.9477 - val_loss: 0.2124 - val_accuracy: 0.9425\n",
            "Epoch 3/15\n",
            "250/250 [==============================] - 13s 53ms/step - loss: 0.1607 - accuracy: 0.9540 - val_loss: 0.1620 - val_accuracy: 0.9550\n",
            "Epoch 4/15\n",
            "250/250 [==============================] - 14s 57ms/step - loss: 0.1471 - accuracy: 0.9574 - val_loss: 0.1271 - val_accuracy: 0.9671\n",
            "Epoch 5/15\n",
            "250/250 [==============================] - 14s 57ms/step - loss: 0.1381 - accuracy: 0.9615 - val_loss: 0.1254 - val_accuracy: 0.9679\n",
            "Epoch 6/15\n",
            "250/250 [==============================] - 14s 54ms/step - loss: 0.1367 - accuracy: 0.9631 - val_loss: 0.1134 - val_accuracy: 0.9696\n",
            "Epoch 7/15\n",
            "250/250 [==============================] - 14s 55ms/step - loss: 0.1201 - accuracy: 0.9681 - val_loss: 0.1345 - val_accuracy: 0.9692\n",
            "Epoch 8/15\n",
            "250/250 [==============================] - 14s 54ms/step - loss: 0.1152 - accuracy: 0.9711 - val_loss: 0.1051 - val_accuracy: 0.9750\n",
            "Epoch 9/15\n",
            "250/250 [==============================] - 14s 56ms/step - loss: 0.0964 - accuracy: 0.9769 - val_loss: 0.0746 - val_accuracy: 0.9842\n",
            "Epoch 10/15\n",
            "250/250 [==============================] - 14s 56ms/step - loss: 0.0731 - accuracy: 0.9844 - val_loss: 0.0491 - val_accuracy: 0.9908\n",
            "Epoch 11/15\n",
            "250/250 [==============================] - 13s 53ms/step - loss: 0.0640 - accuracy: 0.9872 - val_loss: 0.0477 - val_accuracy: 0.9908\n",
            "Epoch 12/15\n",
            "250/250 [==============================] - 13s 53ms/step - loss: 0.0445 - accuracy: 0.9914 - val_loss: 0.0267 - val_accuracy: 0.9962\n",
            "Epoch 13/15\n",
            "250/250 [==============================] - 14s 57ms/step - loss: 0.0262 - accuracy: 0.9954 - val_loss: 0.0222 - val_accuracy: 0.9962\n",
            "Epoch 14/15\n",
            "250/250 [==============================] - 14s 58ms/step - loss: 0.0325 - accuracy: 0.9940 - val_loss: 0.0216 - val_accuracy: 0.9967\n",
            "Epoch 15/15\n",
            "250/250 [==============================] - 14s 55ms/step - loss: 0.0192 - accuracy: 0.9970 - val_loss: 0.0200 - val_accuracy: 0.9967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7feec004f850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epmX5E5ZShB_",
        "outputId": "1c5fceda-ceca-478f-b929-00d7f0e99d07"
      },
      "source": [
        "reber_sample = [\"BTBTSSXXTVVETE\", \"BPBPVPXVPXVPXVVEPE\"]\n",
        "non_reber_sample = [\"BTBTSSPXSETE\", \"BPBPVSPSEPE\"]\n",
        "\n",
        "X_test = reber_sample + non_reber_sample\n",
        "\n",
        "X_test_encoded = tf.ragged.constant( [char_to_int(i, vocabulary) for i in X_test], ragged_rank=1)\n",
        "y_pred = model.predict(X_test_encoded)\n",
        "\n",
        "for i in range(len(y_pred)):\n",
        "    print(\"{}: {:.3f}%\".format(X_test[i], 100 * y_pred[i][0]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BTBTSSXXTVVETE: 98.982%\n",
            "BPBPVPXVPXVPXVVEPE: 99.300%\n",
            "BTBTSSPXSETE: 0.075%\n",
            "BPBPVSPSEPE: 0.003%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP4WKwcCSj2Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}